max(mydata$Ozone[mydata$Month==5 & !is.na(mydata$Ozone)])
?mean
mean(1:10)
mean(1:5)
(1+2+3+4+5)/5
(1+2+3+4+5)/5
max(mydata$Ozone[mydata$Month==5 & !is.na(mydata$Ozone)])
max(mydata$Ozone[mydata$Month==5 & !is.na(mydata$Ozone)])
library(swirl)
x<-list(a=1:20, b=rnorm(10))
lapply(x,mean)
y<-1:9
lappy(y, runif)
lapply(y, runif)
lapply(y, runif, min=9, max=5)
lapply(y, runif, min=0, max=5)
x<-matrix(rnorm(200), 20,20)
x
x<-matrix(rnorm(200), 10,5)
x
apply(x,2,mean)
apply(x,3,mean)
apply(x,1,mean)
apply(x,3,mean)
apply(x,1,mean)
apply(x,2,mean)
apply(x,quantile, probs=c(0.25))
apply(x,1,quantile, probs=c(0.25))
x[1,]
?quantile
apply(x,1,quantile, probs=c(0.25, 0.75))
z<-array(renorm(2*2*10), c(2,2,10))
z<-array(rnorm(2*2*10), c(2,2,10))
z
z<-array(rnorm(2*2*10), c(2,2,5))
z
rep(1,3)
mapply(rep, 1:2)
mapply(rep, 1:2, 1:4,1:5)
mapply(rep, 1:2,2)
mapply(rep, 1:4,4:1)
mapply(rep, 1,4)
mapply(rep, 1:3,3:1)
x<-c(rnorm(5), runif(5), rnorm(5,1))
x
rnorm(5)
rnorm(5,1)
rnorm(5,1)
rnorm(5,1)
?iris
library(datasets)
?library
?data
dat(iris)
data(iris)
View(a)
iris
?mean
tapply(Sepal.Length, Species, mean)["virginica"]
tapply(Sepal.Length, Species, mean)
apply(iris[,1:4],2,mean)
library(datasets)
data("mtcars")
sapply(split(mtcars$mpg, mtcars$cyl), mean)
abs(mean(mtcars$hp[mtcars$cyl==4])-mean(mtcars$hp[mtcars$cyl==8]))
apply(iris, 2, mean)
apply(iris[, 1:4], 2, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
sapply(mtcars, cyl, mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
with(mtcars, tapply(mpg, cyl, mean))
abs(mean(mtcars$hp[mtcars$cyl==4])-mean(mtcars$hp[mtcars$cyl==8]))
tapply(Sepal.Length, Species, mean)["virginica"]
tapply(iris$Sepal.Length, "virginica", mean)
apply(iris[,1],2,mean)
apply(iris[,1:4],2,mean)
apply(iris[,1:4],2,mean)["virginica"]
apply(iris[,1:4],2,mean, na.rm)["virginica"]
apply(iris[,1:4],2,mean, na.rm())["virginica"]
apply(iris[,1:4],2,mean, rm.na())["virginica"]
apply(iris[,1:4],2,mean, rm.na["virginica"]
apply(iris[,1:4],2,mean, rm.na)["virginica"]
apply(iris[,1:4],2,mean, rm.na)["virginica"]
tapply(Sepal.Length, Species, mean)["virginica"]
iris
?tapply
tapply(iris,Sepal.Length, Species, mean)["virginica"]
tapply(iris[,1:4],Sepal.Length, Species, mean)["virginica"]
tapply(iris[,1:4],Sepal.Length, iris$Species, mean)["virginica"]
tapply(iris[,1:4],Sepal.Length,  mean)
tapply(iris[,1:4],  mean)
X<- matrix(rnorm(20), 10, 2)
x
makeCacheMatrix <- function(x = matrix()) {
## set initial value to NULL, clearing existing values
invMatrix <- NULL
## set the value of the  Matrix
set <- function(y) {
x <<- y
invMatrix <<- NULL
}
## get the value of the Matrix
get <- function() x
## set the value to the inverse
setinverse <- function(value) invMatrix <<- value
## get the value of the inverse
getinverse <- function() invMatrix
## List calls
list(set=set, get=get, setinverse=setinverse, getinverse=getinverse)
}
cacheSolve <- function(x, ...) {
## get the cached value
invMatrix <- x$getinverse()
## if not null use the cached one
if(!is.null(invMatrix)) {
message("Cached data.")
## return the cached value
return(invMatrix)
}
## we do not a cached value
data <- x$get()
## lets solve it
invMatrix <- solve(data)
## set the value
x$setinverse(invMatrix)
## return the new value
invMatrix
}
x
makeCacheMatrix(x)
x
cacheSolve(x)
y<-x$getinverse()
y<-x$getinverse$get()
getinverse$get()
x = rbind(c(1, -1/4), c(-1/4, 1))
m = makeCacheMatrix(x)
m$get()
cacheSolve(m)
cacheSolve(m)
makeCacheMatrix <- function(x = matrix()) {
## set initial value to NULL, clearing existing values
invMatrix <- NULL
## get the value of the Matrix
get <- function() x
## get the value of the inverse
getinverse <- function() invMatrix
## set the value of the  Matrix
set <- function(y) {
x <<- y
invMatrix <<- NULL
}
## set the value to the inverse
setinverse <- function(value) invMatrix <<- value
## List calls
list(set=set, get=get, setinverse=setinverse, getinverse=getinverse)
}
cacheSolve(m)
m$get()
q()
m$get()
q()
m$get()
x
solve(x)
?solve
hilbert<-function(n){i<-1:n; 1/outer(i-1,i,"+")}
1:8
?outer
?solve
h8<-hilbert(8)
h8
h8<-hilbert(2)
h8
solve(h8)
1/h8
getwd()
if (!file.exists("data")) {
dir.create("data")
}
getwd()
ls()
dir(0)
dir()
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile = "./data/06hid.csv", method = "curl")
dateDownloaded <- date()
HD <- read.csv("./data/06hid.csv")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile = "./data/06hid.csv")
dateDownloaded <- date()
HD <- read.csv("./data/06hid.csv")
HD[HD$VAL >= 24, 37])
HD[HD$VAL >= 24, 37]
!is.na(HD[HD$VAL >= 24, 37])
sum(!is.na(HD[HD$VAL >= 24, 37]))
HD[ 24, 37]
HD[ 1, 37]
HD[ 1, 37]
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl, destfile = "./data/gas.xlsx")
dateDownloaded <- date()
library(xlsx)
rowIndex = 18 : 23
colIndex = 7 : 15
dat <- read.xlsx("./data/gas.xlsx", sheetIndex = 1, rowIndex = rowIndex,
colIndex = colIndex, header = TRUE)
sum(dat$Zip * dat$Ext, na.rm=T)
library(xlsx)
install.packages(xlsx)
install.packages("rJava")
install.packages("xlsxjars")
install.packages("xlsx")
library(xlsx)
library(xlsx)
library(xlsx)
dat <- read.xlsx("./data/gas.xlsx", sheetIndex = 1, rowIndex = rowIndex,
colIndex = colIndex, header = TRUE)
rowIndex = 18 : 23
colIndex = 7 : 15
dat <- read.xlsx("./data/gas.xlsx", sheetIndex = 1, rowIndex = rowIndex, colIndex = colIndex, header = TRUE)
download.file(fileUrl, destfile = "./data/gas.xlsx", mode='wb')
dateDownloaded <- date()
dat <- read.xlsx("./data/gas.xlsx", sheetIndex = 1, rowIndex = rowIndex, colIndex = colIndex, header = TRUE)
sum(dat$Zip * dat$Ext, na.rm=T)
library(XML)
library(xlsxjars)
library(rJava)
library(XML)
install.packages("XML")
library(XML)
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
rootNode <- xmlRoot(doc)
sum(xpathSApply(rootNode, "//zipcode", xmlValue) == "21231")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileUrl, destfile = "./data/restaurants.xml")
doc
?xpathSApply
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile = "./data/06pid.csv")
dateDownloaded <- date()
DT <- fread("./data/06pid.csv")
library(data.table)
install.packages("data.table")
library(data.table)
DT <- fread("./data/06pid.csv")
race <- 1000
horse1 <- replicate(race, unname(system.time(DT[, mean(pwgtp15), by = SEX]))[1])
system.time({mean(DT[DT$SEX == 1, ]$pwgtp15); mean(DT[DT$SEX == 2, ]$pwgtp15)})
mean(DT$pwgtp15, by = DT$SEX)
horse2 <- replicate(race, unname(system.time(tapply(DT$pwgtp15, DT$SEX, mean)))[1])
horse3 <- replicate(race, unname(system.time(sapply(split(DT$pwgtp15, DT$SEX), mean)))[1])
rowMeans(DT)[DT$SEX == 1]
mean(horse1)
mean(horse2)
mean(horse3)
plot(horse1)
plot(horse2)
plot(horse3)
plot(horse1)
plot(horse2)
plot(horse3)
horse1_av <- cumsum(horse1) / seq_along(horse1)
horse2_av <- cumsum(horse2) / seq_along(horse2)
horse3_av <- cumsum(horse3) / seq_along(horse3)
topY <- max(horse1_av, horse2_av, horse3_av)
lowY <- min(horse1_av, horse2_av, horse3_av)
plot(horse1_av, type = "l", col = "#FF000099", ylim = c(lowY, topY),
xlab = "distance", ylab = "average time")
lines(horse2_av, col = "#0000FF99")
lines(horse3_av, col = "#00000099")
library(XML)
url<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html<-htmlTreeParse(url,useInternalNodes=T)
xpathSApply(html,"//title",xmlValue)
html
grep(html, "title")
xpathSApply(html,"//head",xmlValue)
list()
s <- function(x=3) x
s
s()
s <- function(x<-3) x
s <- function(x <- 3) x
con=url("https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode=readLines(con)
con=url("https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode=readLines(con)
pg1 = GET("http://httpbin.org/basic-auth/:user/:passwd")
library(httr)
pg1 = GET("http://httpbin.org/basic-auth/:user/:passwd")
pg1
pg2 = GET("http://httpbin.org/basic-auth/:user/:passwd",authenticate("user","passwd"))
pg2
pg2 = GET("http://httpbin.org/basic-auth/user/passwd", authenticate("user","passwd"))
pg2
pg2 = GET("http://httpbin.org/basic-auth/user/passwd",authenticate("user","passwd"))
pg2
x<-1:16
quantile(x, probs(0.25,0.5))
quantile(x, probs=(0.25,0.5))
quantile(x, probs=(0.25,0.5)
quantile(x, probs=(0.25,0.5))
x
quantile(x, probs=c(0.25,0.5))
library(httpuv)
library(httr)
install.packages("httpuv")
library(httpuv)
require(httpuv)
require(jasonlite)
install.packages("jsonlite")
library(jsonlite)
require(jasonlite)
require(jsonlite)
oauth_endpoints("github")
myapp <- oauth_app("github",  key = "d66b1ddf5dc9c219f54a",  secret = "81fe085ab2552648b71d220ef717cb9a72f8862e")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
output <- content(req)
list(output[[4]]$name, output[[4]]$created_at)
req
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n=10)
w <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
colNames <- c("filler", "week", "filler", "sstNino12", "filler", "sstaNino12", "filler", "sstNino3", "filler", "sstaNino3", "filler", "sstNino34", "filler", "sstaNino34", "filler", "sstNino4", "filler", "sstaNino4")
d <- read.fwf(url, w, header=FALSE, skip=4, col.names=colNames)
d <- d[, grep("^[^filler]", names(d))]
sum(d[, 4])
connection <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readLines(connection)
close(connection)
c(nchar(htmlCode[10]), nchar(htmlCode[20]), nchar(htmlCode[30]), nchar(htmlCode[100]))
require(httr)
require(XML)
htmlCode <- GET("http://biostat.jhsph.edu/~jleek/contact.html")
content <- content(htmlCode, as="text")
htmlParsed <- htmlParse(content, asText=TRUE)
xpathSApply(htmlParsed, "//title", xmlValue)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
f <- file.path(getwd(), "ss06pid.csv")
download.file(url, f)
acs <- data.table(read.csv(f))
install.packages("data.table", type="source", dependencies=TRUE)
acs <- data.table(read.csv(f))
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv" ,f <- file.path(getwd(), "ss06pid.csv")
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv" f <- file.path(getwd(), "ss06pid.csv")
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
f <- file.path(getwd(), "ss06pid.csv")
download.file(url, f)
acs <- data.table(read.csv(f))
library(data.table)
acs <- data.table(read.csv(f))
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
library(sqldf)
install-package(sqldf)
install.packages(sqlpdf)
install.packages(sql.sqlpdf)
install.packages("sqldf")
library(sqldf)
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
query1
sqldf("select distinct AGEP from acs")
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
file.dest <- 'ACS.csv'
download.file(file.url, file.dest, method='curl' )
ACS <- read.csv('ACS.csv')
getwd()
file.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
file.dest <- "ACS.csv"
download.file(direccion, archivo, method="curl")
download.file(file.url, file.dest, method="curl" )
file.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
file.dest <- "ACS.csv"
download.file(file.url, file.dest, method="curl" )
ACS <- read.csv('ACS.csv')
file.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
file.dest <- "ACS.csv"
download.file(file.url, file.dest, method="curl" )
ACS <- read.csv('getdata_data_ss06hid.csv)
getwd()
ACS <- read.csv('getdata_data_ss06hid.csv)c
ACS <- read.csv("getdata_data_ss06hid.csv")
ACS$agricultureLogical <- ifelse(ACS$ACR==3 & ACS$AGS==6,TRUE,FALSE)
which(ACS$agricultureLogical)
library(jpeg)
install-package(jpeg)
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg?accessType=DOWNLOAD"
download.file(fileUrl, destfile="./data/jeff.jpg",method="curl")
download.file(fileUrl, destfile="./data/jeff.jpg",method="curl")
download.file(fileUrl, destfile="./data/jeff.jpg",method="curl")
direccion2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
archivo2 <- "jeff.jpg"
download.file(direccion2, archivo2, method="curl")
download.file(direccion2, archivo2, method="curl")
library(RCurl)
direccion2 <- getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
direccion2 <- getURL("http://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
file.dest <- 'jeff.jpg'
download.file(file.url, file.dest, mode='wb' )
library(jpeg)
install.packages(jpeg)
install.packages("jpeg")
library(jpeg)
picture <- readJPEG('jeff.jpg', native=TRUE)
quantile(picture, probs = c(0.3, 0.8) )
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP.csv'
download.file(file.url, file.dest )
rowNames <- seq(10,200, 2)
gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
View(gdp)
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
file.dest <- 'GDP2.csv'
download.file(file.url, file.dest )
fed <- read.csv('GDP2.csv')
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
combined[with(combined, order(-V2) )]
View(combined)
combined[with(combined, order(V2) )]
combined[with(combined, order("V2") )]
mean(combined[combined$Income.Group=='High income: OECD',]$V2)
mean(combined[combined$Income.Group=='High income: nonOECD',]$V2)
quentile <- c(0.2,0.4,0.6,0.8,1)
q <- quantile(combined$V2, quentile)
q1 <- combined$V2 <= 38
xtabs(q1 ~ combined$Income.Group)
setwd("~/Getting-and-cleaning-data")
getwwd()
getwd()
trainData = read.csv("UCI HAR Dataset/train/X_train.txt", sep="", header=FALSE)
xTrainData = read.csv("UCI HAR Dataset/train/X_train.txt", sep="", header=FALSE)
setwd("~/Getting-and-cleaning-data")
xTrainData = read.csv("UCI HAR Dataset/train/X_train.txt", sep="", header=FALSE)
View(xTrainData)
subjectTrain = read.csv("UCI HAR Dataset/train/subject_train.txt", sep="", header=FALSE)
View(subjectTrain)
yTrainData = read.csv("UCI HAR Dataset/train/y_train.txt", sep="", header=FALSE)
View(yTrainData)
# x_test
xTestData = read.csv("UCI HAR Dataset/train/X_test.txt", sep="", header=FALSE)
# x_test
xTestData = read.csv("UCI HAR Dataset/test/X_test.txt", sep="", header=FALSE)
View(xTestData)
yTestData = read.csv("UCI HAR Dataset/test/y_test.txt", sep="", header=FALSE)
View(yTestData)
subjectTest = read.csv("UCI HAR Dataset/test/subject_test.txt", sep="", header=FALSE)
names(subjectTrain) <- "subjectID"
names(subjectTest) <- "subjectID"
featureNames =read.csv("UCI HAR Dataset/features.txt")
featureNames =read.csv("UCI HAR Dataset/features.txt")
View(featureNames)
names(xTrainData) <- featureNames$V2
names(xTestData) <- featureNames$V2
View(xTestData)
names(yTrainData) <- "activity"
names(yTestData) <- "activity"
train <- cbind(subjectTrain,yTrainData,xTrainData)
test <- cbind(subjectTest, yTestData,xTestData)
combined <- rbind(train, test)
meanstdcols <- grepl("mean\\(\\)", names(combined)) |  grepl("std\\(\\)", names(combined))
meanstdcols[1:2] <- TRUE
combined <- combined[, meanstdcols]
View(combined)
combined$activity <- factor(combined$activity, labels=c("Walking","Walking Upstairs", "Walking Downstairs", "Sitting", "Standing", "Laying"))
combined$activity <- factor(combined$activity, labels=c("Walking","Walking Upstairs", "Walking Downstairs", "Sitting", "Standing", "Laying")
ohl
combined$activity <- factor(combined$activity, labels=c("Walking","Walking Upstairs", "Walking Downstairs", "Sitting", "Standing", "Laying")
combined$activity <- factor(combined$activity, labels=c("Walking", "Walking Upstairs", "Walking Downstairs", "Sitting", "Standing", "Laying"))c
combined$activity <- factor(combined$activity, labels=c("Walking", "Walking Upstairs", "Walking Downstairs", "Sitting", "Standing", "Laying"))
View(combined)
# create the tidy data set
melted <- melt(combined, id=c("subjectID","activity"))
library(melt)
install.packages("reshape")
library(reshape)
melted <- melt(combined, id=c("subjectID","activity"))
tidy <- dcast(melted, subjectID+activity ~ variable, mean)
install.packages("reshape2")
library(reshape2)
tidy <- dcast(melted, subjectID+activity ~ variable, mean)
install.packages("reshape")
install.packages("reshape")
library(reshape)
melted <- melt(combined, id=c("subjectID","activity"))
tidy <- dcast(melted, subjectID+activity ~ variable, mean)
install.packages("reshape2")
library(reshape2)
View(melted)
tidy <- dcast(melted, subjectID+activity ~ variable, mean)
library(data.table)
tidy <- dcast(melted, subjectID+activity ~ variable, mean)
melted <- melt(combined, id=c("subjectID","activity"))
View(melted)
tidy <- dcast(melted, subjectID+activity ~ variable, mean)
tidy <- dcast(melted, subjectID + activity ~ variable, mean)
tidy <- dcast(melted, "subjectID" + "activity" ~ variable, mean)
tidy <- dcast(melted, subjectID + activity ~ variable, mean)
tidy <- dcast(melted, subjectID + activity, mean)
tidy <- dcast(melted, subjectID+activity, mean)
View(melted)
tidy <- dcast(melted, subjectID+activity~variable, mean)
?dcast
tidy <- acast(melted, subjectID+activity~variable, mean)
